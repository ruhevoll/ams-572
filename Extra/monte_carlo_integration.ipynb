{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5c7f569-b86a-4002-b3ed-0c3825614e0d",
   "metadata": {},
   "source": [
    "Â© Jacob White 2025, All Rights Reserved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8839d45-4f24-483c-a5df-9ee5d686c8a4",
   "metadata": {},
   "source": [
    "# An Introduction to Monte Carlo Integration in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de411f7-4378-4087-8a6d-4ae864f52573",
   "metadata": {},
   "source": [
    "## 1. Monte Carlo Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6911d605-a9a1-4df6-ac68-3221c1db9010",
   "metadata": {},
   "source": [
    "Perhaps the simplest way to introduce Monte Carlo methods is to demonstrate its application in numerical integration. Say we want to compute the integral $$I = \\int_{-1}^1 e^{-x^2} \\ dx \\tag{1}$$ which cannot be computed using elementary methods of calculus. The gyst of the Monte Carlo approach is to sample $N$ points $x_1, \\dots, x_N$ uniformly in $[-1, 1]$, so that (1) can be approximated by $$\\boxed{I = Q_N := \\frac{2}{N} \\sum_{i = 1}^N f(x_i)} \\tag{2}$$ where $f(x) = e^{-x^2}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "34e5058d-d634-4239-be19-31f82fde2451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monte Carlo Approximation: 1.5061745556732637\n",
      "Quadrature Approximation: 1.493648265624854, Quadrature Error: 1.6582826951881447e-14\n",
      "Difference between quadrature and Monte Carlo approximation:-0.012526290048409772\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "N = 100\n",
    "\n",
    "# Draw samples from the uniform distribution on [-1, 1]\n",
    "samples = stats.uniform.rvs(loc = -1, scale = 2, size = N)\n",
    "\n",
    "# Define the function f(x)\n",
    "def f(x):\n",
    "    return np.exp(-x**2)\n",
    "\n",
    "# Compute and print the Monte Carlo approximation\n",
    "approx = 2*sum(map(f, samples))/N\n",
    "print(f'Monte Carlo Approximation: {approx}')\n",
    "\n",
    "from scipy.integrate import quad\n",
    "# Compute using standard numerical quadrature\n",
    "q, error = quad(f, -1, 1)\n",
    "print(f'Quadrature Approximation: {q}, Quadrature Error: {error}')\n",
    "\n",
    "# Difference\n",
    "print(f'Difference between quadrature and Monte Carlo approximation:{q - approx}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c33650-c086-4948-829d-6bdbbd669ed3",
   "metadata": {},
   "source": [
    "### 1.1 General Monte Carlo Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7e59c7-e316-42c5-ae5b-0b4590970162",
   "metadata": {},
   "source": [
    "If we want to compute the multidimensional definite integral $$I = \\int_\\Omega f(\\mathbf{x}) \\ d \\mathbf{x} \\tag{3}$$ using Monte Carlo integration, the approach is similar to the one-dimensional case. We sample points $\\mathbf{x}_1, \\mathbf{x}_2, \\dots, \\mathbf{x}_N$ on $\\Omega$ and compute $$\\boxed{I \\approx Q_N := \\frac{V}{N} \\sum_{i = 1}^N f(\\mathbf{x}_i) = V \\langle f \\rangle\\tag{4}}$$ where $V = \\mathrm{Vol}(\\Omega) = \\int_\\Omega \\ d \\mathbf{x}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb55ef5-3642-49f8-ba8c-794119691d42",
   "metadata": {},
   "source": [
    "> **Example.** Let's approximate the integral $$\\int_{-1}^1 \\int_{-3}^5 x^2 + y^2 \\ dx \\ dy$$ using Monte Carlo integration (the exact answer is $\\frac{320}{3} \\approx 106.6$). The volume of $\\Omega = [-1, 1] \\times [-3, 5]$ is the product of the length of the constituant intervals: $V = 2 \\times 8 = 16$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9525c837-54fc-4a72-9e4f-e96c2e37f235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monte Carlo approximation: 102.3936341694203. Error: -4.273032497246376\n"
     ]
    }
   ],
   "source": [
    "# Draw samples from the rectangle [-1, 1] x [-3, 5] by sampling x and y coordinates separately:\n",
    "N = 100\n",
    "V = 16\n",
    "samples_x = stats.uniform.rvs(loc = -1, scale = 2, size = N)\n",
    "samples_y = stats.uniform.rvs(loc = -3, scale = 8, size = N)\n",
    "samples = np.array([samples_x, samples_y]).T\n",
    "\n",
    "def f(x, y):\n",
    "    return x**2 + y**2\n",
    "\n",
    "# Compute the values of f\n",
    "\n",
    "mcapprox = (V/N)*sum(map(lambda xy: f(*xy), samples))\n",
    "print(f'Monte Carlo approximation: {mcapprox}. Error: {mcapprox - 320/3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395fd5d6-62eb-4197-8014-470f921522df",
   "metadata": {},
   "source": [
    "### 1.2 Error Analysis for Monte Carlo Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01a79eb-f9b7-460f-93e2-0365a43f054d",
   "metadata": {},
   "source": [
    "In this section, we derive an estimation of the error of $Q_N$. Note that $$\\mathrm{Var}(f) = E(\\sigma_N^2) := \\frac{1}{N - 1} \\sum_{i = 1}^N E\\left[(f(\\mathbf{x}_i) - \\langle f\\rangle)^2\\right]$$ and so $$\\mathrm{Var}(Q_N) = \\frac{V^2}{N^2} \\sum_{i = 1}^N \\mathrm{Var}(f) = \\frac{V^2}{N} \\mathrm{Var}(f) = \\frac{V^2}{N} E(\\sigma_N^2).$$ We now use the fact that the sequence $\\{E(\\sigma_1^2), E(\\sigma_2^2)), E(\\sigma_3^2), \\dots\\}$ is bounded due to its limit being $\\mathrm{Var}(f)$, as long as this is assumed finite (?), this variance decreases asymptotically to zero as $1/N$. The estimation of the error of $Q_N$ is thus $$\\boxed{\\delta Q_N \\approx \\sqrt{\\mathrm{Var}(Q_N)} = V \\frac{\\sqrt{\\mathrm{Var}(f)}}{\\sqrt{N}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e330f8d6-1589-499d-8881-f764b51802b0",
   "metadata": {},
   "source": [
    "### 1.3 Bonus: Approximating $\\pi$ using Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bbea4f-6186-4175-ab46-21677e631e31",
   "metadata": {},
   "source": [
    "Consider a square of side length $2r$ and a circle therin of radius $r$. The circle-square area ratio is $$\\frac{\\pi r^2}{4r^2} = \\frac{\\pi}{4}.$$ So, we can randomly sample points in the square of side length $2r$, and compute $$\\pi \\approx 4 \\cdot \\frac{\\text{Number of points in the circle}}{\\text{Total number of points}}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e0c62468-aace-421e-846a-217da84d170a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximation to pi:3.1432000000 \n",
      "Error:0.0016073464102071\n"
     ]
    }
   ],
   "source": [
    "N = 100000\n",
    "r = 1\n",
    "samples_x = stats.uniform.rvs(loc = -r, scale = 2*r, size = N)\n",
    "samples_y = stats.uniform.rvs(loc = -r, scale = 2*r, size = N)\n",
    "\n",
    "points_circ = 0\n",
    "points_square = 0\n",
    "for x, y in zip(samples_x, samples_y):\n",
    "    if x**2 + y**2 <= r**2:\n",
    "        points_circ += 1\n",
    "    else:\n",
    "        points_square += 1\n",
    "\n",
    "result = 4*points_circ/N\n",
    "\n",
    "print(f'Approximation to pi:{result:.10f} ')\n",
    "print(f'Error:{result - np.pi}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e9ebaa-5416-486e-bc5e-0baad61ccb22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
