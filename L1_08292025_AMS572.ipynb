{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c072d6f-c408-4d25-b65c-9202a3879c10",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# AMS 572 - Data Analysis I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7d9103-eb13-4e46-a2f8-3a38b30b9c71",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lecture 1 - August 29, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa653c5-bcb8-442e-bf33-7bdbcfb8d4e0",
   "metadata": {},
   "source": [
    "- Midterm on October 17 (Friday)\n",
    "- Project due December 5\n",
    "- Final on December 18, 2025 (Thursday, 11:15am - 1:45pm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df7a808-7cd1-4bbf-8241-d0975d980bfc",
   "metadata": {},
   "source": [
    "**Discrete random variable**: A random variable $X$ that can take on, at most, a countable number of possible values. It's probability mass function is $$0 \\leq p(x) = P(X = x) \\leq 1.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0488d3d-aa1f-4afd-8faf-93fd2cc30cf3",
   "metadata": {},
   "source": [
    "- For PDFs born out of a discrete random variable, we have the identity: $$\\sum_x p(x) = 1.$$\n",
    "- Another way to describe a discrete random variable is using its **cumulative distribution function**: $$F(x) = P(X \\leq x) = \\sum_{x_i \\leq x} p(x_i).$$ This is a non-decreasing step function for discrete random variables. I.e., if the range of $X$ is $\\{x_1, x_2, \\dots\\}$ where $x_1 < x_2 < \\cdots$, then $F$ is constant on the intervals $[x_i, x_{i + 1})$.\n",
    "- The **expected value** of a discrete random variable $X$ having p.d.f. $p(x)$ is $$E[X] = \\sum_i x_i p(x_i).$$ It is also known as the **mean** $\\mu$ of $X$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f15187-25dd-43b0-8ed9-6ba23caa2468",
   "metadata": {},
   "source": [
    "Some properties of expected value:\n",
    "- $E(c) = c$,\n",
    "- $E[cU(X)] = cE[U(X)]$ (e.g., $U(X) = X^2$),\n",
    "- $E[c_1U_1(X) + c_2U_2(X)] = c_1E[U_1(X)] + c_2E[U_2(X)]$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdf99d6-3169-4eb2-b90e-efbbe4d2d091",
   "metadata": {},
   "source": [
    "**Variance**: If $X$ is a random variable with mean $\\mu$, then the **variance** of $X$, denoted $\\sigma^2$ or $\\mathrm{Var}(X)$, is given by $$\\mathrm{Var}(X) = E[(X - \\mu)^2] = \\sum_i (x_i - \\mu)^2 p(x).$$ This is the \"mean squared deviation\" with respect to $\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7cd479-0064-4dc2-8958-c7000477e10c",
   "metadata": {},
   "source": [
    "Some properties of variance:\n",
    "- $\\mathrm{Var}(c) = 0$,\n",
    "- $\\mathrm{Var}(aX + b) = a^2 \\mathrm{Var}(X)$, $a, b \\in \\mathbb{R}$, \n",
    "- $\\mathrm{Var}(X) = E[(X - \\mu)^2] = E[X^2] - E[X]^2$,\n",
    "- Variance is always positive for $X$ nonconstant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5e1fcf-a8f6-41c5-8339-ae21238902cc",
   "metadata": {},
   "source": [
    "**Standard deviation**: The standard deviation of a random variable $X$ is just the square root of the variance: $$\\mathrm{sd}(X) = \\sqrt{\\mathrm{Var}(X)}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cda9a28-f4a6-42e8-bbc5-e70b9604468e",
   "metadata": {},
   "source": [
    "**Essential examples of distributions**:\n",
    "1. **Binomial distribution**. A binomial experiment is one that possesses the following properties:\n",
    "    1. A Bernoulli (success-failure) trial is performed $n$ times.\n",
    "    2. The trials are independent.\n",
    "    3. The probability of success on a single trial is equal to $p$, remains the same from trial to trial. The probability of failure is $q := (1 - p)$. \n",
    "    4. The random variable of interest is $X$: the number of successes observed during the $n$ trials.\n",
    "    \n",
    "    If $X$ is a binomial random variable, we write $X \\sim Bin(n, p)$ and it has the pdf $$P(X = x) = p(x) = \\binom{n}{x} p^x (1 - p)^{n - x}, \\qquad n = 0, 1, \\dots, n.$$\n",
    "    Some properties:\n",
    "    - $P(X = x) = p(x)$ is a p.d.f,\n",
    "    - $E(X) = np$,\n",
    "    - $\\mathrm{Var}(X) = np(1 - p)$,\n",
    "    - When $x$ goes from 0 to $n$, $p(x)$ first increases monotonically reaching its largest value when $x$ is the largest integer less than or equal to $(n + 1)p$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1835cd2a-8260-4031-8bea-d87b4d1c9031",
   "metadata": {},
   "source": [
    "*Example.* There are 3 coins in a bag. When coin 1, 2, and 3 are flipped, they land on heads with probabilities 0.3, 0.8, and 0.6 (respectively). One of these coins is randomly chosen and flipped 8 times.\n",
    "1. What is the probability that the coin landson heads exactly 3 out of the 8 flips?\n",
    "- Let $X$ = number of heads. We condition based on what coin is being chosen. $$P(X = 3) = \\sum P(X = 3 | C = k) P(C = k) = \\frac{1}{3}\\left[\\binom{8}{3} 0.3^3 0.7^5 + \\binom{8}{3} 0.8^3 0.2^5 + \\binom{8}{3} 0.6^4 0.4^5\\right] \\approx 0.11.$$\n",
    "2. Given that the last 3 of these 8 flips lands on head, what is the conditional probability that exactly 6 out of the 8 flips lands on head?\n",
    "- We compute the conditional probability $$P(X = 6 | X_6, X_7, X_8 = H) = \\frac{\\frac{1}{3}\\left[\\binom{5}{3} 0.3^3 0.7^2 0.3^3 + \\binom{5}{3} 0.8^3 0.2^2 0.8^3 + \\binom{5}{3} 0.6^3 0.4^2 0.6^3\\right]}{\\frac{1}{3} \\left[0.3^3 + 0.8^3 + 0.6^3\\right]}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309f1c25-cb21-4a92-85f6-9bdff875054f",
   "metadata": {},
   "source": [
    "2. **Poisson distribution**. A random variable $X$ taking on one of the values $0, 1, 2, \\dots$ is said to be a **Poisson random variable with parameter $\\lambda$** if for some $\\lambda > 0$, the p.d.f. of $X$ is $$P(X = x) = p(x) = \\frac{e^{-\\lambda} \\lambda^x}{x!}, \\qquad x = 0, 1, 2, \\dots.$$ $X$ is said to have a Poisson distribution with parameter $\\lambda$ and is denoted as $X \\sim \\mathrm{Poisson}(\\lambda)$ or $X \\sim \\mathrm{Po}(\\lambda)$ or $X \\sim P(\\lambda)$. \n",
    "\n",
    "    Some properties of Poisson random variables:\n",
    "    - $E(X) = \\lambda$,\n",
    "    - $\\mathrm{Var}(\\lambda)$,\n",
    "    - If $X \\sim P(\\lambda)$, then $P(X = x)$ increases monotonically and then decerases monotonically as $x$ increasing, reaching maximum when $x$ is the largest integer not exceeding $\\lambda$.\n",
    "\n",
    "    For $n \\geq 20, p \\leq 0.05$, the Poisson distribution usually gives a good approximation to the Binomial distribution. As $\\lambda \\to \\infty$, the Poisson distribution starts to look normal (consequence of central limit theorem)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60273e11-6a2d-482b-8109-91ecf7c0bd49",
   "metadata": {},
   "source": [
    "*Example*. Suppose that on average 1 person in 1000 make a numerical error in preparing his/her income tax return. If 10,000 people selected at random are examined, find an approximation for the probability that 6 or more of the forms will be in error. \n",
    "- Let $X$ be the random variable representing the number of forms that are in error. Then, $$P(X \\geq 6) = 1 - P(X < 6) = 1 - \\sum_{x = 0}^5 \\binom{10000}{x} 0.001^x 0.9999^{10,000-x}= 0.933.$$ Using the Poisson approximation to the Binomial distribution with $\\lambda = np = 10$, $$P(X \\leq 6) \\approx 1 - \\sum_{x = 0}^5 \\frac{e^{-10}10^x}{x!} \\approx 0.932914.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acb000d-e8e6-423c-a24d-959dacd3b5ca",
   "metadata": {},
   "source": [
    "**Continuous random variables**: Any measurable function $X: \\Omega \\to \\mathbb{R}$. It satisfies the following conditions with respect to its p.d.f.:\n",
    "1. $f(x) \\geq 0$,\n",
    "2. $\\int_\\Omega f(x) \\ dx = 1$, where $\\Omega$ is the space of $X$. E.g., $$\\int_{-\\infty}^\\infty f(x) \\ dx = 1,$$\n",
    "3. The probability of an event $A$ is $\\int_A f(x) \\ dx = P(X \\in A)$. \n",
    "\n",
    "The c.d.f. of a random variable $X$ is given by $$F(x) = P(X \\leq x) = \\int_{-\\infty}^x f(t) \\ dt.$$\n",
    "\n",
    "The expectation of $X$ is $$\\mu = E[X] = \\int_\\Omega f(x) \\ dx.$$ Variance, standard deviation, etc. are defined the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce74c5d0-12e9-4509-be7b-22a946d89d28",
   "metadata": {},
   "source": [
    "**Moment generating function**: The moment generating function of a random variable $X$ is the function $M(t)$ given by $$M(t) = E(e^{tX}), \\qquad (t \\in \\mathbb{R}).$$ It gets its name because all of the moments of $X$ can be obtained by successfully differentiating $M(t)$ then evaluating at $t = 0$. \n",
    "- $M'(0) = E(X)$, \n",
    "- $M''(0) = E(X^2)$, \n",
    "- $\\mathrm{Var}(X) = M''(0) - [M'(0)]^2$,\n",
    "- Third moment is skewness,\n",
    "- Fourth moment is kurtosis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2524f489-0282-4085-acf9-e5ef0aa619ae",
   "metadata": {},
   "source": [
    "**Normal distribution**: $X$ is distributed as a normal random variable if its p.d.f. is $$f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{1}{2\\sigma^2}(x - \\mu)^2}, \\qquad x \\in \\mathbb{R}$$ where $\\sigma^2$ and $\\mu$ are the parameters. Denote $$X \\sim N(\\mu, \\sigma^2).$$\n",
    "\n",
    "If $Z = (X - \\mu)/\\sigma \\sim N(0, 1)$. Then the c.d.f. of the *standard normal distribution* is $$\\Phi(x) = P(Z \\leq x) = \\int_{-\\infty}^x \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2}t^2} \\ dt.$$\n",
    "- Moment generating function for $Z \\sim N(0, 1)$, $$M(t) = E(e^{tZ}) = \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^\\infty e^{tz}e^{-z^2/2} \\ dz = \\frac{e^{t^2/2}}{\\sqrt{2\\pi}} \\int_{-\\infty}^\\infty e^{-(z - t)^2/2} \\ dz = e^{t^2/2}.$$\n",
    "- If $X = \\sigma Z + \\mu$, then $$M_X(t) = E(e^{t(\\sigma Z + \\mu)}) = E(e^{t\\sigma Z}e^{t\\mu}) = e^{t\\mu} (e^{tZ})^\\sigma = e^{\\sigma^2 \\frac{t^2}{2} + t\\mu}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7206da05-d566-4b3e-bd7a-b7898186d5e0",
   "metadata": {},
   "source": [
    "**Transformations of random variables**: Given the pdf of a random variable $X$, what is the pdf of $Y = g(X)$ for some function $g$?\n",
    "1. *Method 1: CDF based method* (Works for every transformation). Let $X$ be a continuous random variable with pdf $f_X$ and $Y = X^2$. What is $f_Y(y)$? \n",
    "- $$F_Y(y) = P(Y \\leq y) = P(X^2 \\leq y) = P(-\\sqrt{y} \\leq X \\leq \\sqrt{y})  = F_x(\\sqrt{y}) - F_X(-\\sqrt{y}) = \\frac{1}{2\\sqrt{y}} [f_X(\\sqrt{y}) + f_X(-\\sqrt{y})]$$\n",
    "- How about if $X \\sim N(0, 1)$. What is the pdf of $Y = X^2$? We have $$f_Y(y) = \\frac{1}{2\\sqrt{2\\pi y}}\\left(e^{-y/2} + e^{-y/2}\\right)$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
